{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multithreading and Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Threading\n",
    "* typically, concurrency is created so that we can do some task while I/O is happening (e.g., a server can start processing a new request while waiting for data from a previous request to arrive)\n",
    "* we can create objects that appear to be running independently, but simultaneously\n",
    "* the job of threading is to enable an application to be responsive\n",
    "* CPython, the default implementation of Python, has a Global Interpreter Lock (GIL), which prevents your application from doing two things at once, but rather, the CPU time is being rationed across your threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Simple threading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class InputReader(Thread):\n",
    "    \"\"\"Thread example, extends Thread class\"\"\"\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Whatever is in the run method (or called from\n",
    "        it) is executed in a separate thread\n",
    "        \"\"\"\n",
    "        self.line_of_text = input('Enter some text: ')\n",
    "\n",
    "input('Are you ready? When you hit return the thread will start.')\n",
    "thread = InputReader() # create thread object\n",
    "thread.start() # cf. thread.run() for no concurrency\n",
    "\n",
    "count, result = 1, 1\n",
    "\n",
    "while thread.is_alive():\n",
    "    result = count * count\n",
    "    count += 1\n",
    "\n",
    "print('calculated squares up to {0:,} * {0:,} = {1:,}'\n",
    "      .format(count, result))\n",
    "print('while you typed \"{}\"'.format(thread.line_of_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "\n",
    "cities = ['Boulder', 'Atlanta', 'San Francisco',\n",
    "          'Reno', 'Honolulu', 'Zurich', 'Dubai',\n",
    "          'Dublin', 'Hyderabad', 'Rome']\n",
    "\n",
    "class TempGetter(Thread):\n",
    "    def __init__(self, city):\n",
    "        \"\"\"Initialize our thread\n",
    "\n",
    "In the previous example, our class which extended\n",
    "Thread did not need an __init__ method, because\n",
    "there was no per-thread information to store. Which\n",
    "means that the __init__ method from the superclass\n",
    "(Thread) was called automatically. Here, because we\n",
    "need to store per-thread information (the city), we\n",
    "have to explicitly call the__init__ method of Thread.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.city = city\n",
    "\n",
    "    def run(self):\n",
    "        url_template = (\n",
    "            'http://api.openweathermap.org/data/2.5/' \n",
    "            'weather?q={}&units=imperial'\n",
    "                        '&&APPID=10d4440bbaa8581bb8da9bd1fbea5617')\n",
    "        response = urlopen(url_template.format(self.city))\n",
    "        data = json.loads(response.read().decode())\n",
    "        self.temperature = data['main']['temp']\n",
    "        \n",
    "threads = [TempGetter(c) for c in cities] # creates 10 threads\n",
    "start = time.time()\n",
    "\n",
    "# start all 10 threads\n",
    "for thread in threads:\n",
    "    thread.start() # not run()\n",
    "\n",
    "# wait for all 10 threads to complete\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "for thread in threads:\n",
    "    print(f\"it is {thread.temperature:.0f}°F in {thread.city}\")\n",
    "print(f\"Got {len(threads)} temps in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 getweather.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Threading (cont'd)\n",
    "* the main problem with threads is also their primary advantage–shared memory\n",
    " * all threads have access to all the memory\n",
    " * what if two threads access the same data?\n",
    "* synchronization is the solution, but it's tricky\n",
    " * bugs due to incorrect synchronization can be very difficult to find due to ordering issues\n",
    "* one solution is to force communication between threads to occur using a data structure that has built in locking, such as queue.Queue\n",
    "* disadvantages could be outweighed by the fact that shared memory is FAST, except for the GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lab: threads\n",
    "* create a program which uses threads to simulate a database server\n",
    "* your \"database server\" should simply be a thread which sleeps for a random interval (check out __`time.sleep()`__ and __`random.randint()`__ if you're not familiar with them)\n",
    "* your main thread should get input from the user and respond to it (perhaps reversing the input given by the user) while the database thread is busy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multiprocessing\n",
    "* the Python multiprocessing library is designed for cases where CPU-bound jobs needs to happen in parallel and multiple cores are available\n",
    "* advantages\n",
    " * separate memory space for each process\n",
    " * code is usually straightforward compared to threads\n",
    " * avoids GIL limitation\n",
    " * eliminates synchronization (assuming no shared memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Simple Multiprocessing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, cpu_count\n",
    "import time\n",
    "import os\n",
    "\n",
    "class MuchCPU(Process):\n",
    "    def run(self):\n",
    "        print(os.getpid()) # get process ID\n",
    "        for i in range(80_000_000):\n",
    "            result = i * i\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    print('Running...')\n",
    "    procs = [MuchCPU() for f in range(2)]\n",
    "    t = time.time()\n",
    "\n",
    "    for p in procs:\n",
    "        p.run()\n",
    "    \n",
    "    #for p in procs:\n",
    "        #p.join()\n",
    "    \n",
    "    print('work took {} seconds'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiprocessing (cont'd)\n",
    "* no reason for more processes than there are processors\n",
    " * only `cpu_count()` procs can run simultaneously\n",
    " * each proc consumes resources with a full copy of Python interpreter\n",
    " * interproc communication is expensive\n",
    " * creating procs takes a nonzero amount of time\n",
    "* so we create at most `cpu_count()` processes when the program starts and have them execute tasks as needed\n",
    "* easy to implement a basic series of communicating processes to do this, but it can be tricky to debug, test, and get correct–we don't have to do all this work because the Python developers have already done it for us–multiprocessing pools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiprocessing Pools\n",
    "* pools abstract away the overhead of figuring out what code is running in main process and what code is running in subprocess\n",
    "* abstraction restricts the number of places that code in different processes interact with each other, making it easier to keep track of\n",
    "* pools also hide the passing of data between processes\n",
    " * using a pool looks much like a function call–you pass data into a function, it's executed in another process or processes, and when the work is complete, a value is returned\n",
    " * under the hood, a lot of work is being done to support this–objects in one process are being pickled (serialized) and passed into a pipe, then another process retrieves data from the pipe and unpickles it. Work is done in the subprocess and a result is produced. The result is pickled and passed into a pipe. Eventually, the original process unpickles it and returns it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiprocessing Pool Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import os\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "def prime_factor(value, level=0):\n",
    "    factors = []\n",
    "    if level:\n",
    "        print('    ' * level, 'prime_factor(', value, ', ', level, ') ', os.getpid(), sep='')\n",
    "        pass\n",
    "    for divisor in range(2, value - 1):\n",
    "        quotient, remainder = divmod(value, divisor)\n",
    "        if not remainder:\n",
    "            factors.extend(prime_factor(divisor, level + 1))\n",
    "            factors.extend(prime_factor(quotient, level + 1))\n",
    "            break\n",
    "    else:\n",
    "        factors = [value]\n",
    "    return factors\n",
    "\n",
    "if __name__ == '__main__': # distiguishes between running and importing\n",
    "    pool = Pool()\n",
    "\n",
    "    to_factor = [\n",
    "        random.randint(40_000_000, 80_000_000) \n",
    "                for _ in range(64)\n",
    "    ]\n",
    "    print(to_factor)\n",
    "    results = pool.map(prime_factor, to_factor)\n",
    "    for value, factors in zip(to_factor, results):\n",
    "        print(\"The factors of {} are {}\".format(value, factors))\n",
    "    #print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lab: Multiprocessing Pool\n",
    "* write a program to compute 1!…48! using a multiprocessing pool\n",
    "* won't be much of a parallelism example, but it's easy to code\n",
    "* use previous example as a template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multithreading/Multiprocessing for Python 3\n",
    "* Python 3.2 introduced the __`concurrent.futures`__ module for multithreading  via the ThreadPoolExecutor, or multiprocessing, using ProcessPoolExecutor\n",
    "* it's been backported to Python 2.6+ and can be installed using __`pip install futures`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "URLS = ['https://www.japan.go.jp/',\n",
    "        'http://www.foxnews.com/',\n",
    "        'http://www.cnn.com/',\n",
    "        'http://www.python.org',\n",
    "        'http://www.wikipedia.org',\n",
    "        'http://europe.wsj.com/',\n",
    "        'http://www.bbc.co.uk/',\n",
    "        'http://www.apple.com',\n",
    "        'http://blahblahblah.org']\n",
    "\n",
    "# Retrieve a single page and report the URL and contents\n",
    "def load_url(url, timeout):\n",
    "    with urllib.request.urlopen(url, timeout=timeout) as conn:\n",
    "        return conn.read()\n",
    "\n",
    "start = time.time()\n",
    "# We use a with statement to ensure threads are cleaned up promptly\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # start the load operations and mark each future with its URL\n",
    "    future_to_url = {\n",
    "        executor.submit(load_url, url, 60): url for url in URLS }\n",
    "    \n",
    "    # asynchronously wait for threads to complete...\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print(f'{url} generated an exception: {exc}')\n",
    "        else:\n",
    "            print(f'{url} is {len(data)} bytes')\n",
    "            \n",
    "print(f'Completed in {time.time() - start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial():\n",
    "    start = time.time()\n",
    "    for url in URLS:\n",
    "        try:\n",
    "            data = load_url(url, 60)\n",
    "        except Exception as exc:\n",
    "            print(f'{url} generated an exception: {exc}')\n",
    "        else:\n",
    "            print(f'{url} is {len(data)} bytes')\n",
    "            \n",
    "    print(f'Completed in {time.time() - start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "PRIMES = [\n",
    "    112272535095293,\n",
    "    112582705942171,\n",
    "    112272535095293,\n",
    "    115280095190773,\n",
    "    115797848077099,\n",
    "    1099726899285419]\n",
    "\n",
    "def is_prime(n):\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "\n",
    "    sqrt_n = int(math.floor(math.sqrt(n)))\n",
    "    \n",
    "    for i in range(3, sqrt_n + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):\n",
    "            print(f'{number} is prime: {prime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 5 main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial():\n",
    "    for prime in PRIMES:\n",
    "        print(f'{prime} is prime: {is_prime(prime)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 5 serial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}